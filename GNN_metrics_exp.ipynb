{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experimenting new graph generative model evaluation metrics with GIN\n",
    "\n",
    "Implementation of the whole GNN-based Evaluation workflow.\n",
    "In short :\n",
    "\n",
    "1. Initialization and Training of a graph classifier model using GIN.\n",
    "1. Computing Graph embeddings using the trained models.\n",
    "1. Computing evaluation metrics by computing distance metrics between embedddings of sets of graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Libraries Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from models.training_GIN import train, test\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from util import load_graph_list,perturb_new_rewire\n",
    "from util import load_synth_data, separate_data , load_graph_asS2Vgraph\n",
    "from models.graphcnn import GraphCNN\n",
    "from GNN_metrics import compute_gnn_metrics\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from itertools import product\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training a graph classifier model using Graph Isomorphism Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hyperparameters\n",
    "By default, we use an hyperparameter configuration already use with GIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = None\n",
    "device = 0\n",
    "batch_size = 32\n",
    "iters_per_epoch = 50\n",
    "epochs = 60\n",
    "lr = 0.01\n",
    "seed = 0\n",
    "fold_idx = 1\n",
    "num_layers = [5]\n",
    "num_mlp_layers = 2\n",
    "hidden_dims = [64]\n",
    "final_dropout = 0.5\n",
    "graph_pooling_type = \"sum\"\n",
    "neighbor_pooling_type = \"sum\"\n",
    "learn_eps = False\n",
    "degree_as_tag = True\n",
    "filename = \"\"\n",
    "random = 0\n",
    "degree_feature= False\n",
    "onehot_degree= True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initialize dataset for the graph classification task\n",
    "\n",
    "The graph dataset consist in multiple classes corresponding to types of graphs generated from stocastic models :\n",
    "1. Watts-Strogatz graphs\n",
    "1. Barabasi-Albert graphs\n",
    "1. 2-Community graphs\n",
    "1. 2-Community (small) graphs\n",
    "1. Ladder graphs\n",
    "1. Grid graphs\n",
    "1. 5 classes of ER graphs \"equivalent\" to the WS,BA,2-Com (Large and Small) and Grid graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "# classes: 11\n",
      "# maximum node tag: 77\n",
      "# data: 5100\n"
     ]
    }
   ],
   "source": [
    "row_list=[]\n",
    "\n",
    "#set up seeds and gpu device\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:\" + str(device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "graphs, num_classes, tagset , lentagset = load_synth_data(True, random, onehot_degree, True,degree_feature)\n",
    "\n",
    "grid_graph=[]\n",
    "\n",
    "for i in range(10,20):\n",
    "    for j in range(10,20):\n",
    "        grid_graph.append(nx.grid_2d_graph(i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\graphRL\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "epoch: 1: 100%|██████████| 50/50 [00:03<00:00, 13.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 41.839385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2:   6%|▌         | 3/50 [00:00<00:01, 27.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.665359 test: 0.668627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2: 100%|██████████| 50/50 [00:01<00:00, 28.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 17.587871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3:   6%|▌         | 3/50 [00:00<00:01, 26.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.794118 test: 0.790196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3: 100%|██████████| 50/50 [00:02<00:00, 20.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 15.325890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4:   6%|▌         | 3/50 [00:00<00:01, 28.65batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.900654 test: 0.903922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4: 100%|██████████| 50/50 [00:01<00:00, 26.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 5.904821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5:   6%|▌         | 3/50 [00:00<00:01, 27.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.929630 test: 0.925490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5: 100%|██████████| 50/50 [00:01<00:00, 26.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 6.789541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6:   6%|▌         | 3/50 [00:00<00:01, 27.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.938562 test: 0.941176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6: 100%|██████████| 50/50 [00:02<00:00, 20.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 4.358609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7:   6%|▌         | 3/50 [00:00<00:02, 23.14batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999346 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7: 100%|██████████| 50/50 [00:01<00:00, 27.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 4.613489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8:   8%|▊         | 4/50 [00:00<00:01, 29.49batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.998039 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8: 100%|██████████| 50/50 [00:01<00:00, 28.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.486786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9:   6%|▌         | 3/50 [00:00<00:01, 27.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.990850 test: 0.994118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9: 100%|██████████| 50/50 [00:02<00:00, 21.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.492254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 10:   6%|▌         | 3/50 [00:00<00:01, 26.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 10: 100%|██████████| 50/50 [00:01<00:00, 28.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.738931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 11:   6%|▌         | 3/50 [00:00<00:01, 29.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999346 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 11: 100%|██████████| 50/50 [00:01<00:00, 29.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.438378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 12:   8%|▊         | 4/50 [00:00<00:01, 31.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 12: 100%|██████████| 50/50 [00:02<00:00, 21.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.771951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 13:   6%|▌         | 3/50 [00:00<00:01, 28.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.996514 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 13: 100%|██████████| 50/50 [00:01<00:00, 28.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.082413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 14:   6%|▌         | 3/50 [00:00<00:01, 25.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.997821 test: 0.998039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 14: 100%|██████████| 50/50 [00:01<00:00, 28.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.771314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 15:   6%|▌         | 3/50 [00:00<00:01, 28.92batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 15: 100%|██████████| 50/50 [00:02<00:00, 21.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.658933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 16:   6%|▌         | 3/50 [00:00<00:01, 27.34batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.998257 test: 0.998039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 16: 100%|██████████| 50/50 [00:01<00:00, 29.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.308250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 17:   6%|▌         | 3/50 [00:00<00:01, 27.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 17: 100%|██████████| 50/50 [00:01<00:00, 28.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.173874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 18:   6%|▌         | 3/50 [00:00<00:01, 28.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 18: 100%|██████████| 50/50 [00:02<00:00, 21.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.286695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 19:   6%|▌         | 3/50 [00:00<00:01, 26.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 19: 100%|██████████| 50/50 [00:01<00:00, 28.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.247902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 20:   6%|▌         | 3/50 [00:00<00:01, 28.92batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 20: 100%|██████████| 50/50 [00:01<00:00, 28.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.912285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 21:   6%|▌         | 3/50 [00:00<00:01, 28.92batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 21: 100%|██████████| 50/50 [00:02<00:00, 20.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.623238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 22:   6%|▌         | 3/50 [00:00<00:01, 26.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.995643 test: 0.996078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 22: 100%|██████████| 50/50 [00:01<00:00, 28.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.313729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 23:   6%|▌         | 3/50 [00:00<00:01, 29.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.998911 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 23: 100%|██████████| 50/50 [00:01<00:00, 28.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.223584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 24:   6%|▌         | 3/50 [00:00<00:01, 29.21batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 24: 100%|██████████| 50/50 [00:02<00:00, 21.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.741338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 25:   6%|▌         | 3/50 [00:00<00:01, 26.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.998911 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 25: 100%|██████████| 50/50 [00:01<00:00, 28.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 2.029607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 26:   6%|▌         | 3/50 [00:00<00:01, 28.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999129 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 26: 100%|██████████| 50/50 [00:01<00:00, 28.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 16.309372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 27:   6%|▌         | 3/50 [00:00<00:01, 28.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.996296 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 27: 100%|██████████| 50/50 [00:02<00:00, 20.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.997842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 28:   6%|▌         | 3/50 [00:00<00:01, 24.26batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 28: 100%|██████████| 50/50 [00:01<00:00, 28.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.863009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 29:   6%|▌         | 3/50 [00:00<00:01, 29.49batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 29: 100%|██████████| 50/50 [00:01<00:00, 28.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.420141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 30:   6%|▌         | 3/50 [00:00<00:01, 28.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 30: 100%|██████████| 50/50 [00:02<00:00, 20.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.502037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 31:   6%|▌         | 3/50 [00:00<00:01, 26.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 31: 100%|██████████| 50/50 [00:01<00:00, 28.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.944449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 32:   6%|▌         | 3/50 [00:00<00:01, 28.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 32: 100%|██████████| 50/50 [00:01<00:00, 28.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.441451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 33:   6%|▌         | 3/50 [00:00<00:01, 27.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 33: 100%|██████████| 50/50 [00:02<00:00, 21.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.415809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 34:   6%|▌         | 3/50 [00:00<00:01, 26.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 34: 100%|██████████| 50/50 [00:01<00:00, 28.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.608906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 35:   6%|▌         | 3/50 [00:00<00:01, 27.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.998911 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 35: 100%|██████████| 50/50 [00:01<00:00, 28.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 2.704975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 36:   6%|▌         | 3/50 [00:00<00:01, 28.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 36: 100%|██████████| 50/50 [00:01<00:00, 28.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 4.618137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 37:   6%|▌         | 3/50 [00:00<00:01, 27.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.998693 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 37: 100%|██████████| 50/50 [00:01<00:00, 28.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 4.854105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 38:   6%|▌         | 3/50 [00:00<00:01, 29.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.997821 test: 0.998039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 38: 100%|██████████| 50/50 [00:01<00:00, 28.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.833214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 39:   6%|▌         | 3/50 [00:00<00:01, 26.39batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.998911 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 39: 100%|██████████| 50/50 [00:01<00:00, 28.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 2.333001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 40:   6%|▌         | 3/50 [00:00<00:01, 27.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999129 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 40: 100%|██████████| 50/50 [00:01<00:00, 27.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.019132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 41:   8%|▊         | 4/50 [00:00<00:01, 30.16batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 41: 100%|██████████| 50/50 [00:01<00:00, 28.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 2.299351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 42:   6%|▌         | 3/50 [00:00<00:01, 29.49batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999129 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 42: 100%|██████████| 50/50 [00:02<00:00, 20.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.720693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 43:   6%|▌         | 3/50 [00:00<00:01, 24.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.998039 test: 0.998039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 43: 100%|██████████| 50/50 [00:01<00:00, 27.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.512326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 44:   6%|▌         | 3/50 [00:00<00:01, 27.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 44: 100%|██████████| 50/50 [00:01<00:00, 28.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.751845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 45:   6%|▌         | 3/50 [00:00<00:01, 28.92batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.995425 test: 0.996078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 45: 100%|██████████| 50/50 [00:02<00:00, 21.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.892971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 46:   6%|▌         | 3/50 [00:00<00:01, 27.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 46: 100%|██████████| 50/50 [00:01<00:00, 27.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 1.026585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 47:   6%|▌         | 3/50 [00:00<00:01, 27.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999346 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 47: 100%|██████████| 50/50 [00:01<00:00, 26.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.531589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 48:   6%|▌         | 3/50 [00:00<00:01, 25.71batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 48: 100%|██████████| 50/50 [00:01<00:00, 27.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.572920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 49:   6%|▌         | 3/50 [00:00<00:01, 26.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999346 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 49: 100%|██████████| 50/50 [00:01<00:00, 27.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.817085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 50:   6%|▌         | 3/50 [00:00<00:01, 25.71batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 50: 100%|██████████| 50/50 [00:02<00:00, 19.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.504182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 51:   6%|▌         | 3/50 [00:00<00:01, 27.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 51: 100%|██████████| 50/50 [00:01<00:00, 27.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.242980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 52:   6%|▌         | 3/50 [00:00<00:01, 28.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 52: 100%|██████████| 50/50 [00:01<00:00, 26.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.623075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 53:   6%|▌         | 3/50 [00:00<00:01, 28.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 53: 100%|██████████| 50/50 [00:02<00:00, 20.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.173629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 54:   6%|▌         | 3/50 [00:00<00:01, 26.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 54: 100%|██████████| 50/50 [00:01<00:00, 27.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.305384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 55:   6%|▌         | 3/50 [00:00<00:01, 27.35batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 55: 100%|██████████| 50/50 [00:01<00:00, 27.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.139764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 56:   6%|▌         | 3/50 [00:00<00:01, 27.35batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 56: 100%|██████████| 50/50 [00:01<00:00, 28.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.134514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 57:   6%|▌         | 3/50 [00:00<00:01, 26.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 57: 100%|██████████| 50/50 [00:01<00:00, 27.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.149420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 58:   6%|▌         | 3/50 [00:00<00:01, 27.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 58: 100%|██████████| 50/50 [00:01<00:00, 26.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.231088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 59:   6%|▌         | 3/50 [00:00<00:01, 28.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 1.000000 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 59: 100%|██████████| 50/50 [00:02<00:00, 21.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.236195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 60:   6%|▌         | 3/50 [00:00<00:01, 26.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train: 0.999564 test: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 60: 100%|██████████| 50/50 [00:01<00:00, 28.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training: 0.164309\n",
      "accuracy train: 0.999782 test: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# fold_test_accuracy=[]\n",
    "# fold_train_accuracy=[]\n",
    "row_list=[]\n",
    "for num_layer,hidden_dim in product(num_layers,hidden_dims):\n",
    "\n",
    "    for h in range(1): # Training loops ( >1 if training multiple times )\n",
    "        train_graphs, test_graphs = separate_data(graphs, seed, 1)\n",
    "\n",
    "        model = GraphCNN(num_layer, num_mlp_layers, train_graphs[0].node_features.shape[1], hidden_dim, num_classes, final_dropout, learn_eps, graph_pooling_type, neighbor_pooling_type,random, device).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            scheduler.step()\n",
    "\n",
    "            avg_loss = train(iters_per_epoch,batch_size,model, device, train_graphs, optimizer, criterion,epoch)\n",
    "            acc_train, acc_test = test( model, device, train_graphs, test_graphs, epoch)\n",
    "            # fold_test_accuracy.append(acc_test)\n",
    "            # fold_train_accuracy.append(acc_train)\n",
    "        # row_list.append(get_fid('../../generated_graphs/grid_GRANMixtureBernoulli_DFS.p',5,model))\n",
    "        # row_list.append(get_fid('../../generated_graphs/grid_RNN_BFS.p',5,model))\n",
    "        # row_list.append(get_fid('../../generated_graphs/grid_RNN_MLP_BFS.p',5,model))\n",
    "        # for i in np.arange(0,1.1,0.1):\n",
    "        #     row_list.append(get_fid_synth(perturb_new_rewire(ba_graph,i),1,model,str(i)))\n",
    "\n",
    "    # train_acc.append((np.mean(fold_train_accuracy),num_layer,hidden_dim))\n",
    "    # test_acc.append((np.mean(fold_test_accuracy),num_layer,hidden_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Computing Graph embeddings using the trained GIN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gnn_metrics(filename,graph_dataset,label,model):\n",
    "    \"\"\"\n",
    "    Get the gnn-based metrics (FD,PRDC), comparing the graphs from the file data with\n",
    "    with the reference one used as graphs during GIN training\n",
    "    :param filename: string\n",
    "    :param graph_dataset: set of networkx graphs\n",
    "    :param label: the corresponding integer label for the given class of graphs (eg. if measuring Watts Strogatz = 1)\n",
    "    :param model: the trained instance of the classifier model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    graph_gen = load_graph_list(filename,False)\n",
    "    g_list,_=load_graph_asS2Vgraph(graph_gen,label,random,tagset,lentagset,onehot=onehot_degree,degree_feature=degree_feature)\n",
    "    fid,prdc=compute_gnn_metrics([graph_dataset[i] for i in range(len(graph_dataset)) if graph_dataset[i].label ==label],g_list,model)\n",
    "    print(filename+\" fid : \",fid)\n",
    "    print(filename+\" prdc : \", prdc)\n",
    "\n",
    "    return {\"filename\":filename,\"FD\":fid,\"PRDC\":prdc}\n",
    "\n",
    "def get_gnn_metrics_synth(graph,graph_dataset,label,model,name):\n",
    "    \"\"\"\n",
    "    Get the gnn-based metrics (FD,PRDC), comparing the graphs from the given with\n",
    "    with the reference one used as graphs during GIN training\n",
    "    :param graph: set of networkx graphs\n",
    "    :param graph_dataset: set of networkx graphs\n",
    "    :param label: the corresponding integer label for the given class of graphs (eg. if measuring Watts Strogatz = 1)\n",
    "    :param model: the trained instance of the classifier model\n",
    "    :param name: a string to name the given measured set of graphs (eg. \"Grid\", \"GraphRNN-DFS Grid\", etc)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    g_list,_=load_graph_asS2Vgraph(graph,label,random,tagset,lentagset,onehot=onehot_degree,degree_feature=degree_feature)\n",
    "    fid,prdc=compute_gnn_metrics([graph_dataset[i] for i in range(len(graph_dataset)) if graph_dataset[i].label ==label],g_list,model)\n",
    "    print(\" fid : \",fid)\n",
    "    print(\" prdc : \", prdc)\n",
    "\n",
    "    return {\"filename\":name,\"FD\":fid,\"PRDC\":prdc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Using computed graphs embeddings for experiments\n",
    "\n",
    "Experiments :\n",
    "1. Measuring GNN-based metrics for an increasingly dissimilar set of graphs ( by randomly rewiring edges of ones graphs)\n",
    "2. Measuring GNN-based metrics for sets of graphs from several epochs of a trained generative graphs model ( here, GRAN on grid graphs)\n",
    "3. Comparing GraphRNN and GRAN generated sets of graphs compared to a reference set of graphs (Grid experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1) Perturbation Experiment\n",
    "Perturbing a graph using random edge rewiring (at an increasing ratio from 0=base graph, to 1=random graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  -0.00011094785440945998\n",
      " prdc :  {'precision': 1.0, 'recall': 1.0, 'density': 0.9800000000000001, 'coverage': 1.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  19258.326319264503\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  47343.591335743076\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  63303.994141755094\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  79244.87520859012\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  97988.89749523191\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  124504.54456177163\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  162644.00054658964\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  216473.8683657018\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  277162.5327181018\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      " fid :  354108.50567696214\n",
      " prdc :  {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>FD</th>\n",
       "      <th>PRDC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>{'precision': 1.0, 'recall': 1.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>19258.326319</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>47343.591336</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30000000000000004</td>\n",
       "      <td>63303.994142</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>79244.875209</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>97988.897495</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6000000000000001</td>\n",
       "      <td>124504.544562</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7000000000000001</td>\n",
       "      <td>162644.000547</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>216473.868366</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>277162.532718</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>354108.505677</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename             FD  \\\n",
       "0                   0.0      -0.000111   \n",
       "1                   0.1   19258.326319   \n",
       "2                   0.2   47343.591336   \n",
       "3   0.30000000000000004   63303.994142   \n",
       "4                   0.4   79244.875209   \n",
       "5                   0.5   97988.897495   \n",
       "6    0.6000000000000001  124504.544562   \n",
       "7    0.7000000000000001  162644.000547   \n",
       "8                   0.8  216473.868366   \n",
       "9                   0.9  277162.532718   \n",
       "10                  1.0  354108.505677   \n",
       "\n",
       "                                                 PRDC  \n",
       "0   {'precision': 1.0, 'recall': 1.0, 'density': 0...  \n",
       "1   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "2   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "3   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "4   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "5   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "6   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "7   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "8   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "9   {'precision': 0.0, 'recall': 0.0, 'density': 0...  \n",
       "10  {'precision': 0.0, 'recall': 0.0, 'density': 0...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a new set of grid graph ( from the same data distribution\n",
    "# as the one from the GNN classifier training dataset )\n",
    "grid_graph=[]\n",
    "for i in range(10,20):\n",
    "    for j in range(10,20):\n",
    "        grid_graph.append(nx.grid_2d_graph(i,j))\n",
    "\n",
    "perturb_results = [] # Initializing list of gnn metrics results for each sets of perturbed graphs\n",
    "for i in np.arange(0,1.1,0.1):\n",
    "    perturb_results.append(get_gnn_metrics_synth(perturb_new_rewire(grid_graph,i),graphs,5,model,str(i)))\n",
    "perturb_results_df = pd.DataFrame(perturb_results)\n",
    "perturb_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2) Model Selection Experiment\n",
    "Taking several set of graphs from several epochs of the training phase of one generative model (eg GRAN on Grid graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0000300.p fid :  29926.133367172246\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0000300.p prdc :  {'precision': 0.34, 'recall': 1.0, 'density': 0.35800000000000004, 'coverage': 0.67}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0000600.p fid :  14765.325564828256\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0000600.p prdc :  {'precision': 0.33, 'recall': 1.0, 'density': 0.30000000000000004, 'coverage': 0.77}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0000900.p fid :  5368.885847922869\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0000900.p prdc :  {'precision': 0.73, 'recall': 1.0, 'density': 0.738, 'coverage': 0.94}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0001200.p fid :  135824.7961792889\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0001200.p prdc :  {'precision': 0.02, 'recall': 1.0, 'density': 0.014000000000000002, 'coverage': 0.06}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0001500.p fid :  798.4419287409346\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0001500.p prdc :  {'precision': 0.74, 'recall': 0.99, 'density': 0.75, 'coverage': 0.96}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0001800.p fid :  1726.2745213395938\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0001800.p prdc :  {'precision': 0.79, 'recall': 1.0, 'density': 0.782, 'coverage': 0.94}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0002100.p fid :  1856.2255551621038\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0002100.p prdc :  {'precision': 0.74, 'recall': 1.0, 'density': 0.73, 'coverage': 0.94}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0002400.p fid :  3228.6040817445155\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0002400.p prdc :  {'precision': 0.75, 'recall': 1.0, 'density': 0.754, 'coverage': 0.96}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0002700.p fid :  3852.612151831763\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0002700.p prdc :  {'precision': 0.8, 'recall': 1.0, 'density': 0.778, 'coverage': 0.96}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0003000.p fid :  323.90707624417155\n",
      "grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_0003000.p prdc :  {'precision': 0.83, 'recall': 1.0, 'density': 0.8180000000000001, 'coverage': 0.96}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>FD</th>\n",
       "      <th>PRDC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>29926.133367</td>\n",
       "      <td>{'precision': 0.34, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>14765.325565</td>\n",
       "      <td>{'precision': 0.33, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>5368.885848</td>\n",
       "      <td>{'precision': 0.73, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>135824.796179</td>\n",
       "      <td>{'precision': 0.02, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>798.441929</td>\n",
       "      <td>{'precision': 0.74, 'recall': 0.99, 'density':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>1726.274521</td>\n",
       "      <td>{'precision': 0.79, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>1856.225555</td>\n",
       "      <td>{'precision': 0.74, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>3228.604082</td>\n",
       "      <td>{'precision': 0.75, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>3852.612152</td>\n",
       "      <td>{'precision': 0.8, 'recall': 1.0, 'density': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...</td>\n",
       "      <td>323.907076</td>\n",
       "      <td>{'precision': 0.83, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename             FD  \\\n",
       "0  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...   29926.133367   \n",
       "1  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...   14765.325565   \n",
       "2  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...    5368.885848   \n",
       "3  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...  135824.796179   \n",
       "4  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...     798.441929   \n",
       "5  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...    1726.274521   \n",
       "6  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...    1856.225555   \n",
       "7  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...    3228.604082   \n",
       "8  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...    3852.612152   \n",
       "9  grid_graph_gran\\grid_GRANMixtureBernoulli_DFS_...     323.907076   \n",
       "\n",
       "                                                PRDC  \n",
       "0  {'precision': 0.34, 'recall': 1.0, 'density': ...  \n",
       "1  {'precision': 0.33, 'recall': 1.0, 'density': ...  \n",
       "2  {'precision': 0.73, 'recall': 1.0, 'density': ...  \n",
       "3  {'precision': 0.02, 'recall': 1.0, 'density': ...  \n",
       "4  {'precision': 0.74, 'recall': 0.99, 'density':...  \n",
       "5  {'precision': 0.79, 'recall': 1.0, 'density': ...  \n",
       "6  {'precision': 0.74, 'recall': 1.0, 'density': ...  \n",
       "7  {'precision': 0.75, 'recall': 1.0, 'density': ...  \n",
       "8  {'precision': 0.8, 'recall': 1.0, 'density': 0...  \n",
       "9  {'precision': 0.83, 'recall': 1.0, 'density': ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_graph=[]\n",
    "for i in range(10,20):\n",
    "    for j in range(10,20):\n",
    "        grid_graph.append(nx.grid_2d_graph(i,j))\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "dir = os.fsencode(\"grid_graph_gran\")\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    filename=os.fsdecode(file)\n",
    "    comparison_results.append(get_gnn_metrics(\"grid_graph_gran\\\\\"+filename,graphs,5,model))\n",
    "comparison_results_df = pd.DataFrame(comparison_results)\n",
    "comparison_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3) Model Comparison Experiment (Grid experiment)\n",
    "Taking several set of graphs from generative models (here, GRAN vs GraphRNN vs GraphRNN-S on Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "saved_graphs\\grid_GRANMixtureBernoulli_DFS.p fid :  323.90707624417155\n",
      "saved_graphs\\grid_GRANMixtureBernoulli_DFS.p prdc :  {'precision': 0.83, 'recall': 1.0, 'density': 0.8180000000000001, 'coverage': 0.96}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "saved_graphs\\grid_RNN_BFS.p fid :  37102.80277746646\n",
      "saved_graphs\\grid_RNN_BFS.p prdc :  {'precision': 0.11, 'recall': 0.03, 'density': 0.034, 'coverage': 0.03}\n",
      "# classes: 1\n",
      "# maximum node tag: 77\n",
      "# data: 100\n",
      "Num real: 100 Num fake: 100\n",
      "saved_graphs\\grid_RNN_MLP_BFS.p fid :  53662.08717673054\n",
      "saved_graphs\\grid_RNN_MLP_BFS.p prdc :  {'precision': 0.0, 'recall': 0.41, 'density': 0.0, 'coverage': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>FD</th>\n",
       "      <th>PRDC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saved_graphs\\grid_GRANMixtureBernoulli_DFS.p</td>\n",
       "      <td>323.907076</td>\n",
       "      <td>{'precision': 0.83, 'recall': 1.0, 'density': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saved_graphs\\grid_RNN_BFS.p</td>\n",
       "      <td>37102.802777</td>\n",
       "      <td>{'precision': 0.11, 'recall': 0.03, 'density':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saved_graphs\\grid_RNN_MLP_BFS.p</td>\n",
       "      <td>53662.087177</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.41, 'density': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename            FD  \\\n",
       "0  saved_graphs\\grid_GRANMixtureBernoulli_DFS.p    323.907076   \n",
       "1                   saved_graphs\\grid_RNN_BFS.p  37102.802777   \n",
       "2               saved_graphs\\grid_RNN_MLP_BFS.p  53662.087177   \n",
       "\n",
       "                                                PRDC  \n",
       "0  {'precision': 0.83, 'recall': 1.0, 'density': ...  \n",
       "1  {'precision': 0.11, 'recall': 0.03, 'density':...  \n",
       "2  {'precision': 0.0, 'recall': 0.41, 'density': ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_graph=[]\n",
    "for i in range(10,20):\n",
    "    for j in range(10,20):\n",
    "        grid_graph.append(nx.grid_2d_graph(i,j))\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "dir = os.fsencode(\"saved_graphs\")\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    filename=os.fsdecode(file)\n",
    "    comparison_results.append(get_gnn_metrics(\"saved_graphs\\\\\"+filename,graphs,5,model))\n",
    "comparison_results_df = pd.DataFrame(comparison_results)\n",
    "comparison_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
